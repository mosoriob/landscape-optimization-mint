{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from glob import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import geopandas as gpd\n",
    "import shapely.speedups\n",
    "from shapely.geometry import MultiPolygon\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.dataframe import from_pandas, concat\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "import math\n",
    "from rasterio.merge import merge\n",
    "import shutil\n",
    "from rasterio.windows import Window\n",
    "from rasterio.transform import Affine\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import box\n",
    "from time import time_ns\n",
    "import heapq\n",
    "import sys\n",
    "\n",
    "import rioxarray as rxr\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_df_dask(file_name):\n",
    "    # read the raster file and convert to a dask dataframe\n",
    "    raster = rasterio.open(file_name)\n",
    "    xmin, ymin, xmax, ymax = raster.bounds\n",
    "    img = raster.read(1)\n",
    "    cnt += 1\n",
    "    loc_names = []\n",
    "    values = []\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[0])):\n",
    "            if img[i][j] > 0:\n",
    "                loc_names.append(str([int(-ymax+complete_bb)//10 + i, int(xmin-complete_lb)//10 + j]))\n",
    "                values.append(img[i][j])\n",
    "    raster.close()\n",
    "    tmp_df = pd.DataFrame({'loc': loc_names, 'intensity': values})\n",
    "    cur_df = from_pandas(tmp_df, chunksize=10000)\n",
    "    return cur_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_to_df_rioxarray(file_name):\n",
    "    # read the raster file and convert to an xarray dataframe\n",
    "    raster  = rxr.open_rasterio(file_name, chunk = 100) # 100 is the chunk size in the x and y direction\n",
    "    raster = raster.rename('intensity')\n",
    "    # print(raster['band'])\n",
    "    df = raster.to_dask_dataframe()\n",
    "    raster.close()\n",
    "    # print(df.head())\n",
    "    df = df.where(df['intensity'] > 0)\n",
    "    # print(df.head())\n",
    "    df = df.dropna()\n",
    "    df['loc'] = df['x'].astype(str) + ',' + df['y'].astype(str)\n",
    "    df = df.drop(columns = ['x', 'y'])\n",
    "    df = df.reset_index()\n",
    "    # print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_all_rasters_heap(df, file_names):\n",
    "    # update the heap with the intensity values of the raster files\n",
    "    exception_file_list = []\n",
    "    cnt = 0\n",
    "    print('In total file num:', len(file_names))\n",
    "\n",
    "    df_concat_list = []\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        cur_df = raster_to_df_rioxarray(file_name)\n",
    "\n",
    "        df_concat_list.append(cur_df)\n",
    "        cnt += 1\n",
    "        if cnt % 1000 == 0:\n",
    "            print('finish', cnt, 'file')\n",
    "        # if cnt == 10:\n",
    "        #     break\n",
    "    # print(type(df_concat_list))\n",
    "    # return df_concat_list\n",
    "    # df = concat(df_concat_list)\n",
    "    # print(type(df))\n",
    "    # return df\n",
    "    print(\"here\")\n",
    "    # calculate the percentile of the intensity values and return\n",
    "    return dd.concat(df_concat_list).groupby('loc')['intensity'].apply(lambda group: np.percentile(group, 95), meta=('intensity', 'f8')).compute()\n",
    "    # percentile_df = df.groupby('loc')['intensity'].apply(lambda group: np.percentile(group, 95), meta=('intensity', 'f8'))\n",
    "    # percentile_df = percentile_df.compute()\n",
    "    # return percentile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total simulated burns = 46804\n",
      "heat array init done\n"
     ]
    }
   ],
   "source": [
    "# load the paths to files from yaml file\n",
    "config_file_name = 'config.yaml'\n",
    "with open(config_file_name, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    rx_burn_units_path = config['rx_burn_units_path']\n",
    "    results_dir = config['results_dir']\n",
    "    intensity_dir = config['intensity_dir']\n",
    "    budget = config['budget']\n",
    "# print(rx_burn_units_path, results_dir, intensity_dir, budget)\n",
    "# exit(1)\n",
    "intensity_file_names = glob(os.path.join(intensity_dir, '*.tif'))\n",
    "total_files = len(intensity_file_names)\n",
    "print('total simulated burns =', total_files)\n",
    "# exit(1)\n",
    "complete_lb, complete_rb, complete_tb, complete_bb = [753003.071258364, 839057.6399108863, 4133476.546731642, 4230634.714689108]\n",
    "transform = Affine(10, 0.0, complete_lb, \n",
    "                0.0, -10, complete_bb)\n",
    "\n",
    "heat_array_area = np.zeros([int(math.ceil(complete_bb - complete_tb))//10,int(math.ceil(complete_rb-complete_lb))//10])\n",
    "\n",
    "print('heat array init done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_array_intensity = np.zeros_like(heat_array_area)\n",
    "heat_array_intensity = heat_array_intensity.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pk/Projects/landscape-optimization/.venv/lib/python3.10/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34867 instead\n",
      "  warnings.warn(\n",
      "/home/pk/Projects/landscape-optimization/.venv/lib/python3.10/site-packages/distributed/worker_memory.py:493: FutureWarning: Parameter memory_target_fraction has been deprecated and will be removed in a future version; please use dask config key distributed.worker.memory.target instead\n",
      "  warnings.warn(\n",
      "/home/pk/Projects/landscape-optimization/.venv/lib/python3.10/site-packages/distributed/worker_memory.py:493: FutureWarning: Parameter memory_target_fraction has been deprecated and will be removed in a future version; please use dask config key distributed.worker.memory.target instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster(n_workers=2,\n",
    "                    threads_per_worker=4,\n",
    "                    memory_target_fraction=0.75,\n",
    "                    memory_limit='6GB')\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total file num: 46804\n",
      "finish 1000 file\n",
      "finish 2000 file\n",
      "finish 3000 file\n",
      "finish 4000 file\n",
      "finish 5000 file\n",
      "finish 6000 file\n",
      "finish 7000 file\n",
      "finish 8000 file\n",
      "finish 9000 file\n",
      "finish 10000 file\n",
      "finish 11000 file\n",
      "finish 12000 file\n",
      "finish 13000 file\n",
      "finish 14000 file\n",
      "finish 15000 file\n",
      "finish 16000 file\n",
      "finish 17000 file\n",
      "finish 18000 file\n",
      "finish 19000 file\n",
      "finish 20000 file\n",
      "finish 21000 file\n",
      "finish 22000 file\n",
      "finish 23000 file\n",
      "finish 24000 file\n",
      "finish 25000 file\n",
      "finish 26000 file\n",
      "finish 27000 file\n",
      "finish 28000 file\n",
      "finish 29000 file\n",
      "finish 30000 file\n",
      "finish 31000 file\n",
      "finish 32000 file\n",
      "finish 33000 file\n",
      "finish 34000 file\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_heat_array = None\n",
    "# new_df_concat_list = update_all_rasters_heap(df_heat_array, intensity_file_names)\n",
    "percentile_df = update_all_rasters_heap(df_heat_array, intensity_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = dd.concat(new_df_concat_list).groupby('loc')['intensity'].apply(lambda group: np.percentile(group, 95), meta=('intensity', 'f8')).compute()\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_df_concat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 705 ms, sys: 46.8 ms, total: 752 ms\n",
      "Wall time: 695 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nd = dd.concat(new_df_concat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dask DataFrame Structure:\n",
       "                  index   band spatial_ref intensity     loc\n",
       " npartitions=100                                            \n",
       "                  int64  int64       int64   float32  object\n",
       "                    ...    ...         ...       ...     ...\n",
       " ...                ...    ...         ...       ...     ...\n",
       "                    ...    ...         ...       ...     ...\n",
       "                    ...    ...         ...       ...     ...\n",
       " Dask Name: concat, 1401 graph layers,\n",
       " 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd, sys.getsizeof(nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_df = nd.groupby('loc')['intensity'].apply(lambda group: np.percentile(group, 95), meta=('intensity', 'f8'))\n",
    "percentile_df = percentile_df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329.0154638290405"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(percentile_df)/(1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('df_list.txt', 'w')\n",
    "f.writelines(str(new_df_concat_list))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = None\n",
    "with open('df_list.txt') as f1:\n",
    "    l = f1.readlines()\n",
    "    f1.close()\n",
    "type(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(heat_array_intensity)):\n",
    "    for j in range(len(heat_array_intensity[0])):\n",
    "        try:\n",
    "            heat_array_intensity[i][j] = percentile_df.loc[str([i, j])]['intensity'] \n",
    "        except:\n",
    "            heat_array_intensity[i][j] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster = rasterio.open(intensity_file_names[1])\n",
    "with rasterio.open(os.path.join(results_dir, 'summed_raster_heatmap_intensity.tif'),\n",
    "                        'w',\n",
    "                        driver='GTiff',\n",
    "                        height = heat_array_area.shape[0],\n",
    "                        width = heat_array_area.shape[1],\n",
    "                        count=1,\n",
    "                        dtype=heat_array_area.dtype,\n",
    "                        crs=raster.crs,\n",
    "                        transform = transform) as dst:\n",
    "            dst.write(heat_array_intensity, 1)\n",
    "            dst.close()\n",
    "raster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
